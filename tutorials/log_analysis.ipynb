{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5279e90c",
   "metadata": {},
   "source": [
    "# Simple Log Analysis with Declare4Py\n",
    "\n",
    "This tutorial will go through the steps necessary to perform a simple analysis of logs with the Declare4Py library.\n",
    "## Instantiation and simple Utility Functions\n",
    "\n",
    "Necessary for this tutorial is the __log_analyzer__ class that contains all the methods for the analysis.\n",
    "For this reason we import __log_analyzer__ from the __Declare4Py__ package and the __os__ package of python. \n",
    "\n",
    "Then set the path of the log, and instantiate an object of the __log_analyzer__ class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10f3035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from log_analyzer import LogAnalyzer\n",
    "\n",
    "\n",
    "log_path = os.path.join(\"..\", \"tests\", \"Sepsis Cases.xes.gz\")\n",
    "\n",
    "loganalyser = LogAnalyzer()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1225a100",
   "metadata": {},
   "source": [
    "The next step is the parsing of the log with the `parse_xes_log` function. Logs can be passed both in the `.xes` or `xes.gz` formats. \n",
    "<br> At the moment we are using the `.xes` parser of PM4PY, which might change in the future. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ae55fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parses a xes log to EventLog\n",
    "loganalyser.parse_xes_log(log_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0eb4454a",
   "metadata": {},
   "source": [
    "The `loganalyser` object holds the parsed log, length of the log, frequent set of items and a binary encoding of the log. The last two attributes will be explained in a later paragraph.\n",
    "<br> Once the log has been successfully parsed, we can get the log itself and its length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def7e392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the parsed log\n",
    "print(f\"This is the log: {loganalyser.get_log()}\")\n",
    "print(\"--------------------------------------\")\n",
    "# Print the number of cases in the log\n",
    "print(f\"This is the log: {loganalyser.get_length()}\")\n",
    "print(\"--------------------------------------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de73d7b9",
   "metadata": {},
   "source": [
    "Two other utility functions are: `get_log_alphabet_payload` and `get_log_alphabet_activities`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a939e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the set of resources that are in the log\n",
    "print(f\"This is the log: {loganalyser.get_log_alphabet_payload()}\")\n",
    "print(\"--------------------------------------\")\n",
    "# Print the set of activities that are in the log\n",
    "print(f\"This is the log: {loganalyser.get_log_alphabet_activities()}\")\n",
    "print(\"--------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e42a7ae",
   "metadata": {},
   "source": [
    "A log is a complex data structure that can be explored along several dimensions. The functions `activities_log_projection` and `resources_log_projection` project the cases in the log according to the activities and resources dimensions, respectively. Each projection is a list (the log) of lists (the single cases) containing the name of the activity/resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77896ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity projection\n",
    "for idx, trace in enumerate(loganalyser.activities_log_projection()):\n",
    "    print(f\"{idx}- {trace}\")\n",
    "print(\"--------------------------------------\")\n",
    "\n",
    "# Resource projection\n",
    "for idx, trace in enumerate(loganalyser.resources_log_projection()):\n",
    "    print(f\"{idx}- {trace}\")\n",
    "print(\"--------------------------------------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b617ba75",
   "metadata": {},
   "source": [
    "## Frequent Itemsets\n",
    "\n",
    "__log_analyzer__ offers support for computing the frequent itemsets of activities/resources in the log. The function `compute_frequent_itemsets` takes as input the `min_support` of the itemsets, the `algorithm` to perform the computation (available `fpgrowth` and `apriori`) and `len_itemset` indicating the maximum length of the itemsets, the default is `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f780d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loganalyser.compute_frequent_itemsets(min_support=0.8, algorithm='fpgrowth', len_itemset=3)\n",
    "print(f\" The most frequent item sets: {loganalyser.get_frequent_item_sets()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3c126bb",
   "metadata": {},
   "source": [
    "## Log Binary Encoding\n",
    "One-hot encoding (i.e. binary encoding) is also provided by this class, which can be useful for Machine Learning tasks or statistical analysis. The function `log_encoding` takes as input the `dimension` and is optional. The default value for this parameter is defaulted to `act`, which are the activity names. It can also be set to `payload`. This function sets the attribute `binary_encoded_log` and returns it, the attribute is a __Pandas__ __DataFrame__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483dc758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding for activities\n",
    "loganalyser.log_encoding(dimension='act')\n",
    "print(f\"One-hot encoding for activities:\\n{loganalyser.get_binary_encoded_log()}\")\n",
    "print(\"--------------------------------------\")\n",
    "\n",
    "# One hot encoding for payload\n",
    "loganalyser.log_encoding(dimension='payload')\n",
    "print(f\"One-hot encoding for payload:\\n{loganalyser.get_binary_encoded_log()}\")\n",
    "print(\"--------------------------------------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6774faa",
   "metadata": {},
   "source": [
    "## Filtering Functions \n",
    "The __log_analyzer__ also offers functions useful for searching relevant data by filtering the log.\n",
    "\n",
    "The first function is `filter_time_range_contained`, which takes as input: \n",
    "- `start_date` as a string of type `2013-01-01 00:00:00`; \n",
    "- `end_date` a string of type `2013-01-01 00:00:00`; \n",
    "- `mode` which is defaulted to `events`, but allows also `traces_intersecting` and `traces_contained` as values; \n",
    "- `timestamp_key` (defaulted to `time:timestamp`) which is the attribute used for the timestamp; \n",
    "- `case_id_key`, the attribute used as identifier and has default value `case:concept:name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8816640b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_log = loganalyser.filter_time_range(\"2013-01-01 00:00:00\", \"2015-12-31 23:59:59\", mode='traces_contained')\n",
    "print(f\"Filtered log for time range: {filtered_log}\")\n",
    "print(\"--------------------------------------\")\n",
    "\n",
    "filtered_log = loganalyser.filter_time_range(\"2013-01-01 00:00:00\", \"2015-12-31 23:59:59\", mode='traces_constrained')\n",
    "print(f\"Filtered log for time range: {filtered_log}\")\n",
    "print(\"--------------------------------------\")\n",
    "\n",
    "filtered_log = loganalyser.filter_time_range(\"2013-01-01 00:00:00\", \"2015-12-31 23:59:59\", mode='events')\n",
    "print(f\"Filtered log for time range: {filtered_log}\")\n",
    "print(\"--------------------------------------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9255a38",
   "metadata": {},
   "source": [
    "The second function is `filter_case_performance` allows to filter the log by a range of minimum performance and maximum performance, which is the duration of a case. It takes as inputs:\n",
    "- `min_performace`: a floating point value that represents the minimum value of the range;\n",
    "- `max_performance`: a floating point value that represents the maximum value of the range;\n",
    "- `timestamp_key`: a string defaulted to `time:timestamp`, which is the attribute to be used for the timestamp;\n",
    "- `case_id_key`: string defaulted to `case:concept:name`, which is the attribute to be used as case identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17128633",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_log = loganalyser.filter_case_performance(86400, 864000)\n",
    "print(f\"Filtered on case performance: {filtered_log}\")\n",
    "print(\"--------------------------------------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ddde21e6",
   "metadata": {},
   "source": [
    "`get_start_activities` is a function that retrieves all starting activities of the log, it takes as inputs:\n",
    "- `activity_key` attribute used for the activity, default value is: `concept:name`;\n",
    "- `timestamp_key` attribute to be used for the timestamp, default values is: `time:timestamp`;\n",
    "- `case_id_key` attribute to be used as case identifier, default value is: `case:concept:name`.\n",
    "\n",
    "`filter_start_activities` allows to filter all the activities that start with the specified set of start activities. It takes as inputs:\n",
    "- `activities` can be either a set or a list. It is the collection of start activities;\n",
    "- `retain` a boolean value that if True, retains the traces containing the given start activities, if false, the traces are dropped, default values is: `True`;\n",
    "- `activity_key` attribute used for the activity, default value is: `concept:name`;\n",
    "- `timestamp_key` attribute to be used for the timestamp, default values is: `time:timestamp`;\n",
    "- `case_id_key` attribute to be used as case identifier, default value is: `case:concept:name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9991b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_start = loganalyser.get_start_activities()\n",
    "print(f\"Start activities: {log_start}\")\n",
    "print(\"--------------------------------------\")\n",
    "\n",
    "filtered_log = loganalyser.filter_start_activities([\"ER Registration\"])\n",
    "print(f\"Filtered on specified start activity: {filtered_log}\")\n",
    "print(\"--------------------------------------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "782b7d5e",
   "metadata": {},
   "source": [
    "The next two functions are very similar to the previous ones, but this time the end activities are used.\n",
    "`get_end_activities` a function that retrieves all the end activities of a log:\n",
    "- `activity_key` attribute used for the activity, default value is: `concept:name`;\n",
    "- `timestamp_key` attribute to be used for the timestamp, default values is: `time:timestamp`;\n",
    "- `case_id_key` attribute to be used as case identifier, default value is: `case:concept:name`.\n",
    "\n",
    "`filter_end_activities` allows to filter all the activities that end with the specified set of end activities. It takes as inputs:\n",
    "- `activities` can be either a set or a list. It is the collection of the end activities;\n",
    "- `activity_key` attribute used for the activity , default value is: `concept:name`;\n",
    "- `retain` a boolean value that if True, retains the traces containing the given start activities, if false, the traces are dropped, default values is: `True`;\n",
    "- `timestamp_key` attribute to be used for the timestamp, default values is: `time:timestamp`;\n",
    "- `case_id_key` attribute to be used as case identifier, default value is: `case:concept:name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa1f112",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_end = loganalyser.get_end_activities()\n",
    "print(f\"End activities: {log_end}\")\n",
    "print(\"--------------------------------------\")\n",
    "\n",
    "filtered_log = loganalyser.filter_end_activities([\"ER Registration\"])\n",
    "print(f\"Filtered on specified end activity: {filtered_log}\")\n",
    "print(\"--------------------------------------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b752a14e",
   "metadata": {},
   "source": [
    "Variants are a crucial part of logs, for this reason the class __log_analyzer__ contains functions that allow to filter logs by variants.\n",
    "\n",
    "The function `get_variants` retrieves __all__ the variants from the log. It takes as inputs:\n",
    "- `activity_key` attribute to be used for the activity, defaults values is: `concept:name`;\n",
    "- `timestamp_key` attribute to be used for the timestamp, default values is: `time:timestamp`;\n",
    "- `case_id_key` attribute to be used as case identifier, default values is: `case:concept:name`.\n",
    "\n",
    "There are two functions that filter by variants: `filter_variants_top_k`, `filter_variants`. One retains the top-k variants of the log, the other filters a log by a specified set of variants, respectively.\n",
    "\n",
    "`filter_variants_top_k` takes as inputs:\n",
    "- `k` number of variants that should be kept;\n",
    "- `activity_key` attribute used for the activity , default value is: `concept:name`;\n",
    "- `timestamp_key` attribute to be used for the timestamp, default values is: `time:timestamp`;\n",
    "- `case_id_key` attribute to be used as case identifier, default value is: `case:concept:name`.\n",
    "\n",
    "`filter_variants` takes as inputs:\n",
    "- `variants` can be either a set or a list. It is the collection of the variants by which we want to filter;\n",
    "- `retain` a boolean value that if True, retains the traces containing the given start activities, if false, the traces are dropped, default values is: `True`;\n",
    "- `activity_key` attribute used for the activity , default value is: `concept:name`;\n",
    "- `timestamp_key` attribute to be used for the timestamp, default values is: `time:timestamp`;\n",
    "- `case_id_key` attribute to be used as case identifier, default value is: `case:concept:name`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb052fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants = loganalyser.get_variants()\n",
    "print(f\"All retrieved variants of loaded log: {variants}\")\n",
    "print(\"--------------------------------------\")\n",
    "\n",
    "filtered_variants = loganalyser.filter_variants_top_k(2)\n",
    "print(f\"Filtered log on cases following one of the k most frequent variants: {filtered_variants}\")\n",
    "print(\"--------------------------------------\")\n",
    "\n",
    "filtered_variants = loganalyser.filter_variants([\"KNA, nan A\"])\n",
    "print(f\"Filtered variants on given collection: {filtered_variants}\")\n",
    "print(\"--------------------------------------\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9eb08b19",
   "metadata": {},
   "source": [
    "Last two functions are `get_event_attribute_values` and `filter_event_attribute_values`. The first one retrieves all the values for a specified (event) attribute, while the second one filters an event log by the values of some event attribute. \n",
    "\n",
    "`get_event_attribute_values` takes as inputs:\n",
    "- `attribute` is the attribute by which we retrieve the events;\n",
    "- `count_once_per_case`  if True, consider only an occurrence of the given attribute value inside a case and if there are multiple events sharing the same attribute value, count only 1 occurrence, default values: `False`; \n",
    "- `case_id_key` attribute to be used as case identifier, default value is: `case:concept:name`.\n",
    "\n",
    "`filter_event_attribute_values` takes as inputs: \n",
    "- `attribute_key` attribute to filter;\n",
    "- `values` admitted (or forbidden) values (accepted both sets and lists);\n",
    "- `level` specifies how the filter should be applied, default values is: `case`, which filters the cases where at least one occurrence happens, `event` filter the events eventually trimming the cases;\n",
    "- `retain` a boolean value that specifies if the values should be kept or removed, default values is: `True`;\n",
    "- `case_id_key` attribute to be used as case identifier, default value is: `case:concept:name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf6f92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = loganalyser.get_event_attribute_values(\"concept:name\")\n",
    "resources = loganalyser.get_event_attribute_values(\"org:resource\")\n",
    "\n",
    "filtered_log = loganalyser.filter_event_attribute_values(\"org:resource\", [\"Resource10\"], level=\"case\", retain=True)\n",
    "filtered_log = loganalyser.filter_event_attribute_values(\"org:resource\", [\"Resource10\"], level=\"case\", retain=False)\n",
    "\n",
    "filtered_log = loganalyser.filter_event_attribute_values(\"org:resource\", [\"Resource10\"], level=\"event\", retain=True)\n",
    "filtered_log = loganalyser.filter_event_attribute_values(\"org:resource\", [\"Resource10\"], level=\"event\", retain=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0 (v3.7.0:1bf9cc5093, Jun 27 2018, 04:59:51) [MSC v.1914 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "05d4b7c3cd0aad81aa9df4db91d3eeeb2841d831664bc3cb6ce2ef5b755f059a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
